---
title: "Exam 3"
author: "Westley Cook"
date: "4/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# standard first load

library(tidyverse)

# for skim()

library(skimr)

# for gt tables

library(gt)

# for tidy()

library(broom)

```

## Question 1: Exploratory Data Analysis

### 1A) My hypothesis

I expect the correlation between number of migrants and the amount of remittances to be positive, because it seems intuitive that the more migrants are in a country, the more people there are who might be sending money home to other countries. Furthermore, I expect the correlation to be somewhat strong, meaning I expect the amount of remittances to rise in a pretty-close-to-linear manner with the number of migrants. I’d like to control for migrants’ income level and country/region of origin though; I imagine migrants’ money-sharing habits may differ by income, and those from poor countries/regions are probably more likely to send money home than those from rich countries/regions.

### 1B) Read and wrangle data

```{r question_1b, echo=FALSE}

# This r chunk loads data on migrants and data on remittances, tidying both
# before joining them by country and year. It then plots remittances by number
# of migrants, modifies the data to transform both variables to a log scale, and
# re-plots the log of remittances by the log of migrants

# loading raw migrant data, specifying col_types to preclude message output

raw_migrants <- read_csv("raw-data/number_migrants.csv", col_types = cols())

# loading raw remittance data, specifying col_types to preclude message output

raw_remittances <- read_csv("raw-data/remittances.csv", col_types = cols())

# tidying migrant data by pivoting. I take all columns with migrant numbers,
# drop the prefix migrants_ from the name, and put the names (now just years)
# under a new "year" variable. I put the values under a new "migrants" variable,
# dropping all NA values

migrants <- raw_migrants %>% 
  pivot_longer(cols = migrants_1990:migrants_2015,
               names_to = "year",
               names_prefix = "migrants_",
               values_to = "migrants",
               values_drop_na = TRUE)

# tidying remittances data in an almost identical way. I take all columns with
# remittance outflow numbers, drop the prefix remittances_ from the name, and
# put the names (now just years) under a new "year" variable. I put the values
# under a new "remittances" variable, dropping all NA values. I also rename
# "Country" to "country" for easy joining with the migrants data

remittances <- raw_remittances %>% 
  pivot_longer(cols = remittances_1990:remittances_2015,
               names_to = "year",
               names_prefix = "remittances_",
               values_to = "remittances",
               values_drop_na = TRUE) %>% 
  rename(country = Country)

# joining the data. I use left_join() to preserve the continents variable in
# migrants and join by country and year. I then use omit any NA values from the
# results and use filter() to get rid of any 0 values under remittances or
# migrants

joined <- left_join(migrants, remittances, by = c("country", "year")) %>% 
  na.omit() %>% 
  filter(remittances != 0,
         migrants != 0)

# plotting remittances by number of migrants, coloring by year. I divide values
# of migrants by 1,000,000 to make x axis values more readable (in millions),
# and divide remittances values by 1,000 to make y axis values more readable (in
# billions, since they were already in millions). I use theme_classic() to get
# rid of formatting clutter and change the color scheme to viridis so the years
# are more clearly distinguishable, also adding legend title while I'm at it. I
# then add a descriptive plot title and subtitle and label the axes

joined %>% 
  ggplot(aes(migrants / 1000000, remittances / 1000, color = year)) +
  geom_point() +
  theme_classic() +
  scale_color_viridis_d(name = "Year") +
  labs(title = "Number of Migrants and Total Remittance Outflows by Year",
       subtitle = "Six linear outlier points on the right are the USA",
       x = "Number of Migrants (millions)",
       y = "Remittance Outflows (billions of USD)")

# adding columns for logged number of migrants and logged remittance outflows

joined <- joined %>% 
  mutate(log_migrants = log(migrants),
         log_remittances = log(remittances))

# plotting logged values in almost the same way as I plotted the other values.
# Only differences in this plot compared to the plot above are the variables I
# use and the descriptive titles and axis labels

joined %>% 
  ggplot(aes(log_migrants, log_remittances, color = year)) +
  geom_point() +
  theme_classic() +
  scale_color_viridis_d(name = "Year") +
  labs(title = "Migrants and Total Remittance Outflows by Year",
       subtitle = "Natural Log Transformation",
       x = "Log Number of Migrants",
       y = "Log Remittance Outflows")

```

### 1C) Interpret correlation coefficients

```{r question_1c, echo=FALSE}

# This r chunk finds the correlation of log_migrants and log_remittances by year
# and prints them in a gt table, rounding the correlation coefficients to three
# digits

# creating correlations tibble by grouping by year and summarizing the
# correlation for each year

correlations <- joined %>% 
  group_by(year) %>% 
  summarize(cor = cor(log_migrants, log_remittances))

# rounding the values in the correlations data to 3 digits (somewhat
# arbitrarily) and piping it through gt() to produce a nice table. I then add a
# descriptive title and subtitle, column labels, and a source note

correlations %>% 
  mutate(cor = round(cor, digits = 3)) %>% 
  gt() %>% 
  tab_header(title = "Correlation between Migrants and Remittances by Year",
             subtitle = "From log-transformed data") %>% 
  cols_label(year = "Year",
             cor = "Correlation") %>% 
  tab_source_note("Sources: UN International Migrant Stock
                  and World Bank Remittance Data")

# Side note: out of curiosity, I also looked at the correlation between migrants
# and remittances for each year (not logged values) and the correlations were
# all about a tenth or more higher than the logged data correlations - getting
# as high as .916 in 2005! I wonder why that is, and which more accurately
# states the degree to which migrants and remittances are correlated. See below

# joined %>% 
#   group_by(year) %>% 
#   summarize(cor = cor(migrants, remittances))

# year  cor
# <chr> <dbl>
#
# 1990	0.7265286			
# 1995	0.7949481			
# 2000	0.8707546			
# 2005	0.9163149			
# 2010	0.8659647			
# 2015	0.8104758	

```

<br>

The correlation coefficient from 2015 supports my hypothesis from 1A. There appears to be a strong positive correlation between the (logged) number of migrants and the (logged) amount of remittance outflows, meaning that an increase in one is closely associated with an increase in the other.

## Question 2: Running and Interpreting Regressions

### 2A) Run a regression 

```{r question_2a, echo=FALSE}

# This r chunk runs a linear regression to find the effect of log_migrants on
# log_remittances, tidying up the results and presenting them in a gt table

# assigning the model

mod <- lm(log_remittances ~ log_migrants, data = joined)

# cleaning the model for display. I use tidy(conf.in = TRUE) to generate the
# lower and upper bounds of a 95% confidence interval, then select the variables
# I'd like to display in the table and round them all to two digits

tidy_mod <- mod %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  mutate(estimate = round(estimate, digits = 2),
         conf.low = round(conf.low, digits = 2),
         conf.high = round(conf.high, digits = 2))

# making a table to display the results. Text for the title, subtitle, and
# column labels were all copied from the assignment prompt

tidy_mod %>% 
  gt() %>% 
  tab_header(title = "Effect of Number of Migrants on Amount of Remittances",
             subtitle = "Both IV and DV are logged") %>% 
  cols_label(term = "Variable",
             estimate = "Estimate",
             conf.low = "Lower Bound",
             conf.high = "Upper Bound")

```

### 2B) Interpret the results 

The estimate for log_migrants is 0.84, which tells us that *on average*, a 1% increase in migrants is associated with an increase of 0.84% for remittances. Unfortunately, we can’t say for certain that this is causal, since we haven’t taken all other possible variables into consideration. There is also an element of uncertainty; the lower and upper bounds of log_migrants indicate that the actual average increase in remittances associated with a 1% increase in migrants could be as low as 0.77% or as high as 0.90%.

The Bayesian interpretation of this interval is that we can be 95% confident (i.e. there’s a 95% chance) that the true average treatment effect on remittances of a 1% increase in migrants lies between 0.77% and 0.90%. The frequentist interpretation is that if we ran this same model repeatedly, it would generate an interval containing the true average treatment effect 95% of the time.

### 2C) Estimate fitted values 

The formula for estimating a fitted value based on our model is

$$ \hat y = b_0 + b_1 * x $$

where $\hat y$ is the predicted value of log_remittances, $b_0$ is the intercept, $b_1$ is the slope coefficient (the estimate of log_migrants from our table in 2A), and $x$ is the value of log_migrants we will use to predict log_remittances. Plugging in values from the table, when the logged number of migrants is 17.69, as it was for the United States in 2015, we get

$$ \hat y = -5.63 + 0.84 * 17.69 = 9.2296 $$

which is essentially the same as R's predict() function outputs. (The predictions differ slightly since we rounded values in the formula.)

```{r question_2c}

# predicting the logged remittances when log_migrants = 17.69

predict(lm(log_remittances ~ log_migrants, data = joined),
        tibble(log_migrants = 17.69))

```




